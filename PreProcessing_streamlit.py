import streamlit as st
import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from imblearn.over_sampling import SMOTE
from collections import Counter
import warnings

warnings.filterwarnings("ignore")  # sklearn thread ê´€ë ¨ ê²½ê³  ë¬´ì‹œ

st.title("ğŸ“Š ì„¼ì„œ ë°ì´í„° ì „ì²˜ë¦¬ í”„ë¡œê·¸ë¨")

uploaded_file = st.file_uploader("CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["csv"])

if uploaded_file is not None:
    df = pd.read_csv(uploaded_file)
    st.write("### ì›ë³¸ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°", df.head())

    st.write("---")
    st.subheader("ğŸ› ï¸ ìˆ˜í–‰í•  ì „ì²˜ë¦¬ ì‘ì—… ì„ íƒ")

    # ì‚¬ìš©ì ì„ íƒ
    apply_datetime = st.checkbox("1. ì‹œê³„ì—´ ì—´ì„ datetimeìœ¼ë¡œ ë³€í™˜")
    apply_corr_missing = st.checkbox("2. ìƒê´€ê´€ê³„+ê²°ì¸¡ì¹˜ ê¸°ë°˜ ì—´ ì œê±° ë° í‰ê·  ëŒ€ì²´")
    apply_passfail_encoding = st.checkbox("3. Pass_Fail ì—´ ì¸ì½”ë”© (-1â†’0, 1â†’1)")
    apply_smote = st.checkbox("4. SMOTEë¡œ ë°ì´í„° ê· í˜• ë§ì¶¤")
    apply_scaling = st.checkbox("5. ì •ê·œí™” (MinMaxScaler)")

    time_column = None
    if apply_datetime:
        time_column = st.selectbox("datetimeìœ¼ë¡œ ë³€í™˜í•  ì—´ ì„ íƒ", df.columns)

    if st.button("ğŸš€ ì „ì²˜ë¦¬ ì‹œì‘"):
        with st.spinner("ì „ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤..."):

            # 1. datetime ë³€í™˜
            if apply_datetime and time_column:
                df[time_column] = pd.to_datetime(df[time_column])

            # 2. ìƒê´€ê´€ê³„ + ê²°ì¸¡ì¹˜ ì²˜ë¦¬
            if apply_corr_missing:
                if 'Pass_Fail' in df.columns:
                    sensor_columns = [col for col in df.columns if 'Sensor' in col and col != 'Pass_Fail']
                    correlations = df[sensor_columns + ['Pass_Fail']].corr()['Pass_Fail'].abs()
                    columns_to_drop = [col for col in sensor_columns if (correlations[col] < 0.05) and (df[col].isna().mean() > 0.1)]
                    df.drop(columns=columns_to_drop, axis=1, inplace=True)
                    df.fillna(df.mean(), inplace=True)

            # 3. Pass_Fail ì¸ì½”ë”©
            if apply_passfail_encoding:
                if 'Pass_Fail' in df.columns:
                    st.write("Pass_Fail ë³€í™˜ ì „ í´ë˜ìŠ¤ ë¶„í¬:")
                    st.write(df['Pass_Fail'].value_counts())
                    df['Pass_Fail'] = df['Pass_Fail'].map({-1: 0, 1: 1})
                    st.write("ë³€í™˜ í›„ í´ë˜ìŠ¤ ë¶„í¬:")
                    st.write(df['Pass_Fail'].value_counts())

            # 4. SMOTE
            if apply_smote:
                try:
                    if 'Pass_Fail' in df.columns:
                        X = df.drop('Pass_Fail', axis=1).select_dtypes(include=[np.number])
                        y = df['Pass_Fail'].astype(int)

                        counter = Counter(y)
                        min_class = min(counter.values())

                        if min_class > 1:
                            smote = SMOTE(random_state=42, k_neighbors=min(min_class - 1, 5))
                            X_resampled, y_resampled = smote.fit_resample(X, y)
                            df = pd.concat([pd.DataFrame(X_resampled, columns=X.columns), pd.Series(y_resampled, name='Pass_Fail')], axis=1)
                        else:
                            st.warning(f"SMOTEë¥¼ ì ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì†Œìˆ˜ í´ë˜ìŠ¤ ë°ì´í„° ìˆ˜ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤ (min class: {min_class})")
                except Exception as e:
                    st.error(f"SMOTE ì ìš© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

            # 5. ì •ê·œí™”
            if apply_scaling:
                sensor_cols = [col for col in df.columns if 'Sensor' in col and col != 'Pass_Fail']
                scaler = MinMaxScaler()
                df[sensor_cols] = scaler.fit_transform(df[sensor_cols])

        st.success("ì „ì²˜ë¦¬ ì™„ë£Œ!")
        st.write("### ì „ì²˜ë¦¬ëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°", df.head())

        # CSV ë‹¤ìš´ë¡œë“œ
        csv = df.to_csv(index=False).encode('utf-8-sig')
        st.download_button("ğŸ“¥ ì „ì²˜ë¦¬ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ", data=csv, file_name='preprocessed_data.csv', mime='text/csv')
